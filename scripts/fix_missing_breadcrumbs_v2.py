#!/usr/bin/env python3
"""
Add BreadcrumbList JSON-LD schema to pages that are missing it.
This handles pages that weren't generated by the generators.
"""

import os
import re
import json
from glob import glob

SITE_DIR = 'site'
BASE_URL = 'https://thecroreport.com'

# Mapping of page paths to their breadcrumb hierarchy
# Format: path -> [{"name": "...", "url": "..."}]
PAGE_BREADCRUMBS = {
    'index.html': [
        {"name": "Home", "url": f"{BASE_URL}"}
    ],
    'about/index.html': [
        {"name": "Home", "url": f"{BASE_URL}"},
        {"name": "About", "url": f"{BASE_URL}/about/"}
    ],
    'consulting/index.html': [
        {"name": "Home", "url": f"{BASE_URL}"},
        {"name": "GTM Consulting", "url": f"{BASE_URL}/consulting/"}
    ],
    'newsletter/index.html': [
        {"name": "Home", "url": f"{BASE_URL}"},
        {"name": "Newsletter", "url": f"{BASE_URL}/newsletter/"}
    ],
}


def generate_breadcrumb_schema(breadcrumbs):
    """Generate BreadcrumbList JSON-LD from breadcrumb list."""
    items = []
    for i, crumb in enumerate(breadcrumbs, 1):
        items.append({
            "@type": "ListItem",
            "position": i,
            "name": crumb["name"],
            "item": crumb["url"]
        })

    schema = {
        "@context": "https://schema.org",
        "@type": "BreadcrumbList",
        "itemListElement": items
    }

    return f'''
    <!-- BreadcrumbList Schema -->
    <script type="application/ld+json">
{json.dumps(schema, indent=2)}
    </script>'''


def get_page_breadcrumbs(filepath):
    """Determine breadcrumbs for a page based on its path."""
    rel_path = os.path.relpath(filepath, SITE_DIR)

    # Check explicit mappings first
    if rel_path in PAGE_BREADCRUMBS:
        return PAGE_BREADCRUMBS[rel_path]

    # Parse path to generate breadcrumbs
    parts = rel_path.split('/')
    if len(parts) < 2:
        return None

    section = parts[0]

    # Companies section
    if section == 'companies' and len(parts) >= 2:
        if parts[1] == 'index.html':
            return [
                {"name": "Home", "url": f"{BASE_URL}"},
                {"name": "Companies", "url": f"{BASE_URL}/companies/"}
            ]
        else:
            company_slug = parts[1]
            # Extract company name from the page
            with open(filepath, 'r') as f:
                content = f.read()
            title_match = re.search(r'<h1[^>]*>([^<]+)</h1>', content)
            company_name = title_match.group(1) if title_match else company_slug.replace('-', ' ').title()

            return [
                {"name": "Home", "url": f"{BASE_URL}"},
                {"name": "Companies", "url": f"{BASE_URL}/companies/"},
                {"name": company_name, "url": f"{BASE_URL}/companies/{company_slug}/"}
            ]

    # Jobs section (stale pages)
    if section == 'jobs' and len(parts) >= 2:
        if parts[1] in ['index.html', 'vp-sales', 'cro-jobs']:
            return None  # Skip category pages for now
        job_slug = parts[1]
        return [
            {"name": "Home", "url": f"{BASE_URL}"},
            {"name": "Jobs", "url": f"{BASE_URL}/jobs/"},
            {"name": "Position Details", "url": f"{BASE_URL}/jobs/{job_slug}/"}
        ]

    return None


def add_breadcrumb_to_page(filepath):
    """Add BreadcrumbList schema to a page."""
    with open(filepath, 'r') as f:
        content = f.read()

    # Skip if already has BreadcrumbList
    if 'BreadcrumbList' in content:
        return False

    breadcrumbs = get_page_breadcrumbs(filepath)
    if not breadcrumbs:
        return False

    schema_html = generate_breadcrumb_schema(breadcrumbs)

    # Find insertion point - before </head>
    head_close = content.find('</head>')
    if head_close == -1:
        print(f"  Warning: No </head> found in {filepath}")
        return False

    content = content[:head_close] + schema_html + '\n' + content[head_close:]

    with open(filepath, 'w') as f:
        f.write(content)

    return True


def main():
    print("=" * 70)
    print("ADDING BREADCRUMBLIST SCHEMA TO PAGES")
    print("=" * 70)

    # Find all pages missing BreadcrumbList
    all_pages = glob(f"{SITE_DIR}/**/index.html", recursive=True)
    missing_breadcrumb = []

    for page in all_pages:
        with open(page, 'r') as f:
            content = f.read()
        if 'BreadcrumbList' not in content:
            missing_breadcrumb.append(page)

    print(f"\nFound {len(missing_breadcrumb)} pages missing BreadcrumbList\n")

    # Process non-job pages first
    non_job_pages = [p for p in missing_breadcrumb if '/jobs/' not in p]
    job_pages = [p for p in missing_breadcrumb if '/jobs/' in p]

    fixed = 0

    print("Processing non-job pages...")
    for page in non_job_pages:
        if add_breadcrumb_to_page(page):
            print(f"  Fixed: {page}")
            fixed += 1

    print(f"\nProcessing {len(job_pages)} stale job pages...")
    job_fixed = 0
    for page in job_pages:
        if add_breadcrumb_to_page(page):
            job_fixed += 1
            if job_fixed % 100 == 0:
                print(f"  Fixed {job_fixed} job pages...")

    fixed += job_fixed

    print(f"\n{'=' * 70}")
    print(f"Results: {fixed} pages fixed")
    print("=" * 70)


if __name__ == '__main__':
    main()
